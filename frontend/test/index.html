<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Web Audio API Reverb Example</title>
  <style>
    body { font-family: sans-serif; background: #111; color: #eee; padding: 2rem; }
    input { margin: 0.5rem 0; }
    button { margin: 1rem 0; }
  </style>
</head>
<body>
  <h1>ğŸ”Š Web Audio API: Ğ ĞµĞ²ĞµÑ€Ğ±ĞµÑ€Ğ°Ñ†Ğ¸Ñ</h1>

  <label>ğŸµ Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»:
    <input type="file" id="audioFile" accept="audio/*" />
  </label><br>

  <label>ğŸŒŒ Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Impulse Response (IR):
    <input type="file" id="irFile" accept="audio/*" />
  </label><br>

  <label>ğŸšï¸ Dry/Wet:
    <input type="range" id="mix" min="0" max="1" step="0.01" value="0.5" />
  </label><br>

  <button id="playBtn">â–¶ï¸ Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ¸</button>

  <p id="status"></p>

  <script>
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    let trackSource;
    let convolver;
    let dryGain, wetGain;

    let audioBuffer, irBuffer;

    const audioInput = document.getElementById('audioFile');
    const irInput = document.getElementById('irFile');
    const mixInput = document.getElementById('mix');
    const playBtn = document.getElementById('playBtn');
    const status = document.getElementById('status');

    audioInput.addEventListener('change', async () => {
      const file = audioInput.files[0];
      if (file) {
        const arrayBuffer = await file.arrayBuffer();
        audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
        status.textContent = `ğŸµ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾: ${file.name}`;
      }
    });

    irInput.addEventListener('change', async () => {
      const file = irInput.files[0];
      if (file) {
        const arrayBuffer = await file.arrayBuffer();
        irBuffer = await audioCtx.decodeAudioData(arrayBuffer);
        status.textContent += ` | ğŸŒŒ IR: ${file.name}`;
      }
    });

    playBtn.addEventListener('click', () => {
      if (!audioBuffer) {
        alert("Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»!");
        return;
      }

      if (!irBuffer) {
        alert("Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸ IR-Ñ„Ğ°Ğ¹Ğ»!");
        return;
      }

      // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº, ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
      if (trackSource) {
        trackSource.stop();
      }

      trackSource = audioCtx.createBufferSource();
      trackSource.buffer = audioBuffer;

      convolver = audioCtx.createConvolver();
      convolver.buffer = irBuffer;

      dryGain = audioCtx.createGain();
      wetGain = audioCtx.createGain();

      dryGain.gain.value = 1 - mixInput.value;
      wetGain.gain.value = mixInput.value;

      trackSource.connect(dryGain);
      trackSource.connect(convolver);

      convolver.connect(wetGain);

      dryGain.connect(audioCtx.destination);
      wetGain.connect(audioCtx.destination);

      trackSource.start();

      status.textContent += ` | â–¶ï¸ Ğ˜Ğ³Ñ€Ğ°ĞµÑ‚...`;
    });

    mixInput.addEventListener('input', () => {
      if (dryGain && wetGain) {
        dryGain.gain.value = 1 - mixInput.value;
        wetGain.gain.value = mixInput.value;
      }
    });
  </script>
</body>
</html>
